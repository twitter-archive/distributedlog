########################
# ZooKeeper Client Settings
########################

# zookeeper settings
zkSessionTimeoutSeconds=30
zkNumRetries=0
zkRetryStartBackoffMillis=100
zkRetryMaxBackoffMillis=200
# bkc zookeeper settings
bkcZKSessionTimeoutSeconds=60
bkcZKNumRetries=20
bkcZKRetryStartBackoffMillis=100
bkcZKRetryMaxBackoffMillis=200

########################
# BookKeeper Client Settings
########################

# bookkeeper client timeouts
bkcWriteTimeoutSeconds=10
bkcReadTimeoutSeconds=1
bkcNumWorkerThreads=16
# bkcNumIOThreads=16
bkc.numChannelsPerBookie=1
bkc.enableTaskExecutionStats=true
bkc.connectTimeoutMillis=1000
bkc.enablePerHostStats=true

########################
# DL Settings
########################

# lock timeout
lockTimeoutSeconds=0
# dl worker threads
numWorkerThreads=16

### Recovery Related Settings

# recover log segments in background
recoverLogSegmentsInBackground=true
# disable max id in proxy
maxIdSanityCheck=true
# use allocator pool for proxy
enableLedgerAllocatorPool=false
# ledger allocator pool size
ledgerAllocatorPoolCoreSize=20
# check stream exists or not
createStreamIfNotExists=true
# encode dc id in version
encodeDCIDInVersion=true
# logSegmentNameVersion
logSegmentNameVersion=1

### Write Performance Related Settings

# ensemble size
ensemble-size=3
write-quorum-size=3
ack-quorum-size=2
bkc.ensemblePlacementPolicy=org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy
bkc.delayEnsembleChange=true

# sync settings
# buffer size is large because when we rewrite we perform a very large write to persist
# all queue state at once (up to max queue memory size, ex. 16MB). the write will be
# throttled if it takes too long, which can hurt performance, so important to optimize
# for this case.
output-buffer-size=512000
enableImmediateFlush=false
periodicFlushFrequencyMilliSeconds=6
logFlushTimeoutSeconds=120

### Ledger Rolling Related Settings

# retention policy
retention-size=0
# rolling ledgers (disable time rolling/enable size rolling)
rolling-interval=0

# max logsegment bytes=2GB
# much larger than max journal size, effectively never roll and let drpc do it
maxLogSegmentBytes=2147483648

# rolling concurrency
logSegmentRollingConcurrency=1
# disable sanityCheckDelete
sanityCheckDelete=false
ledgerAllocatorPoolName=drpc-alloc-pool

### Readahead settings

enableReadAhead=true
ReadAheadBatchSize=10
ReadAheadMaxEntries=100
ReadAheadWaitTime=10

### Rate limit

rpsSoftWriteLimit=1
rpsHardWriteLimit=5
rpsHardServiceLimit=15

### Config

dynamicConfigReloadIntervalSec=5